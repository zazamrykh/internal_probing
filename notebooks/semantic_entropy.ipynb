{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3259ca8e",
   "metadata": {},
   "source": [
    "## Semantic entropy demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffa0b0",
   "metadata": {},
   "source": [
    "This is demonstrational notebook for semantic entropy method use. \n",
    "\n",
    "We will load some real questions from trivia QA and see them\n",
    "\n",
    "Then we will load Mistral 7b model in 8 bit format and infer them on questions N (e. g. 10) times.\n",
    "\n",
    "After we calculate semantic entropy\n",
    "\n",
    "We will do this with as much using original functions from semantc_unsertainty/uncertainty module from github.com/jlko/semantic_uncertainty repository.\n",
    "\n",
    "I cloned it as subtree to that project using git subtree into external/semantic_uncertainty subdirectory. Also I add RoBERTa model instead of deberta because of issues with deberta tokenizer. \n",
    "\n",
    "Another important note: I loaded roberta and mistral using path to local downloaded models. I do it because of troubles with downloading through notebook, for some reasons loading was unsuccessfull so I use cli hf to download models.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7721d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncertainty: /home/zazamrykh/projects/internal_probing/external/semantic_uncertainty/semantic_uncertainty/uncertainty/__init__.py\n",
      "semantic_entropy imports OK\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"external\" / \"semantic_uncertainty\"))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"external\" / \"semantic_uncertainty\" / \"semantic_uncertainty\"))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"external\" / \"semantic_uncertainty\" / \"semantic_uncertainty\" / \"uncertainty\"))\n",
    "\n",
    "\n",
    "import semantic_uncertainty\n",
    "import uncertainty\n",
    "\n",
    "print(\"uncertainty:\", getattr(uncertainty, \"__file__\", None))\n",
    "\n",
    "from semantic_uncertainty.uncertainty.uncertainty_measures.semantic_entropy import (\n",
    "    EntailmentRoBERTa,\n",
    "    get_semantic_ids,\n",
    "    logsumexp_by_id,\n",
    "    predictive_entropy_rao,\n",
    ")\n",
    "print(\"semantic_entropy imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a3e6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1+cu128\n",
      "cuda available: True\n",
      "gpu: NVIDIA GeForce RTX 3060\n",
      "DTYPE=torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "def pick_dtype():\n",
    "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
    "        return torch.bfloat16\n",
    "    return torch.float16\n",
    "\n",
    "DTYPE = pick_dtype()\n",
    "print(f'DTYPE={DTYPE}')\n",
    "\n",
    "# Params\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51603ddf",
   "metadata": {},
   "source": [
    "### Load some samples from dataset with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238f5086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dce63954f7f4b579253bd36fb923321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/mandarjoshi/trivia_qa/resolve/0f7faf33a3908546c6fd5b73a660e0f8ff173c2f/rc.nocontext/validation-00000-of-00001.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/mandarjoshi/trivia_qa/resolve/0f7faf33a3908546c6fd5b73a660e0f8ff173c2f/rc.nocontext/validation-00000-of-00001.parquet\n",
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " dict_keys(['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer']))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "\n",
    "ds_stream = load_dataset(\n",
    "    \"mandarjoshi/trivia_qa\",\n",
    "    \"rc.nocontext\",\n",
    "    split=\"validation\",\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "ds_stream = ds_stream.shuffle(seed=SEED, buffer_size=2_000)\n",
    "\n",
    "sample = list(islice(ds_stream, 10))  # load 10 samples for demo\n",
    "\n",
    "len(sample), sample[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8785dfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>gold_normalized</th>\n",
       "      <th>gold_value_raw</th>\n",
       "      <th>gold_aliases_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tc_2167</td>\n",
       "      <td>Which US city was named after a British Prime ...</td>\n",
       "      <td>[steel city, climate of pittsburgh pennsylvani...</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>[Smoky City, Pittsburgh (Pa.), Pittsburgh, Pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qb_9081</td>\n",
       "      <td>Harold Holt became Prime Minister of which cou...</td>\n",
       "      <td>[australie, orstraya, federal australia, austr...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>[Australia (Commonwealth realm), AustraliA, Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qb_6552</td>\n",
       "      <td>The Suez Canal joins the Red Sea and which oth...</td>\n",
       "      <td>[sea of mediterranea, mediterranian sea, roman...</td>\n",
       "      <td>Mediterranean Sea</td>\n",
       "      <td>[Mediterranian, Meditiranean, West Mediterrane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qb_2020</td>\n",
       "      <td>Selenology is the scientific study of which ce...</td>\n",
       "      <td>[moonless, earth and moon, lunar mass, luna sa...</td>\n",
       "      <td>The moon</td>\n",
       "      <td>[Sol 3a, Moon-like, Mass of the Moon, Solar an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qb_1830</td>\n",
       "      <td>In September 2006 the government of Prime Mini...</td>\n",
       "      <td>[thailand, kingdom of thailand, kingdom of tha...</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>[Muang Thai, Taihland, ISO 3166-1:TH, Thai Emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dpql_452</td>\n",
       "      <td>Anatomy. Where are the intercostal muscles sit...</td>\n",
       "      <td>[between ribs]</td>\n",
       "      <td>Between the RIBS</td>\n",
       "      <td>[Between the RIBS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tc_2090</td>\n",
       "      <td>Who first drew Mickey Mouse when ?Disney first...</td>\n",
       "      <td>[celebrity productions, iwerks ub, ub iwerks, ...</td>\n",
       "      <td>Ub Iwerks</td>\n",
       "      <td>[Iwerks, Ub, Ub Iwerks, Ub Iwerks Studio, Cele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>qb_7419</td>\n",
       "      <td>A quadruped is an animal with how many feet?</td>\n",
       "      <td>[four, 4]</td>\n",
       "      <td>Four</td>\n",
       "      <td>[Four, four, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qz_2194</td>\n",
       "      <td>Who was part man, part machine, all cop and ha...</td>\n",
       "      <td>[robocop 1987 film, robotic police officer, ro...</td>\n",
       "      <td>Robocop</td>\n",
       "      <td>[I'd buy that for a dollar, RoboCop, RobotCop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tc_2250</td>\n",
       "      <td>What kind of disaster claimed some 100,000 liv...</td>\n",
       "      <td>[地震, earth quakes, earthquakes, tectonic earth...</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>[Seism, Earthquake, Seismic event, The kinds o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_id                                           question  \\\n",
       "0     tc_2167  Which US city was named after a British Prime ...   \n",
       "1     qb_9081  Harold Holt became Prime Minister of which cou...   \n",
       "2     qb_6552  The Suez Canal joins the Red Sea and which oth...   \n",
       "3     qb_2020  Selenology is the scientific study of which ce...   \n",
       "4     qb_1830  In September 2006 the government of Prime Mini...   \n",
       "5    dpql_452  Anatomy. Where are the intercostal muscles sit...   \n",
       "6     tc_2090  Who first drew Mickey Mouse when ?Disney first...   \n",
       "7     qb_7419       A quadruped is an animal with how many feet?   \n",
       "8     qz_2194  Who was part man, part machine, all cop and ha...   \n",
       "9     tc_2250  What kind of disaster claimed some 100,000 liv...   \n",
       "\n",
       "                                     gold_normalized     gold_value_raw  \\\n",
       "0  [steel city, climate of pittsburgh pennsylvani...         Pittsburgh   \n",
       "1  [australie, orstraya, federal australia, austr...          Australia   \n",
       "2  [sea of mediterranea, mediterranian sea, roman...  Mediterranean Sea   \n",
       "3  [moonless, earth and moon, lunar mass, luna sa...           The moon   \n",
       "4  [thailand, kingdom of thailand, kingdom of tha...           Thailand   \n",
       "5                                     [between ribs]   Between the RIBS   \n",
       "6  [celebrity productions, iwerks ub, ub iwerks, ...          Ub Iwerks   \n",
       "7                                          [four, 4]               Four   \n",
       "8  [robocop 1987 film, robotic police officer, ro...            Robocop   \n",
       "9  [地震, earth quakes, earthquakes, tectonic earth...         Earthquake   \n",
       "\n",
       "                                    gold_aliases_raw  \n",
       "0  [Smoky City, Pittsburgh (Pa.), Pittsburgh, Pen...  \n",
       "1  [Australia (Commonwealth realm), AustraliA, Co...  \n",
       "2  [Mediterranian, Meditiranean, West Mediterrane...  \n",
       "3  [Sol 3a, Moon-like, Mass of the Moon, Solar an...  \n",
       "4  [Muang Thai, Taihland, ISO 3166-1:TH, Thai Emp...  \n",
       "5                                 [Between the RIBS]  \n",
       "6  [Iwerks, Ub, Ub Iwerks, Ub Iwerks Studio, Cele...  \n",
       "7                                    [Four, four, 4]  \n",
       "8  [I'd buy that for a dollar, RoboCop, RobotCop,...  \n",
       "9  [Seism, Earthquake, Seismic event, The kinds o...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_gold_normalized(ex):\n",
    "    ans = ex[\"answer\"]\n",
    "    golds = ans.get(\"normalized_aliases\") or []\n",
    "    if not golds:\n",
    "        nv = ans.get(\"normalized_value\")\n",
    "        if nv:\n",
    "            golds = [nv]\n",
    "    return golds\n",
    "\n",
    "rows = []\n",
    "for ex in sample:\n",
    "    rows.append({\n",
    "        \"question_id\": ex.get(\"question_id\"),\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"gold_normalized\": extract_gold_normalized(ex),\n",
    "        \"gold_value_raw\": ex[\"answer\"].get(\"value\"),\n",
    "        \"gold_aliases_raw\": ex[\"answer\"].get(\"aliases\"),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce21893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Which US city was named after a British Prime Minister?\n",
      "Gold normalized: ['steel city', 'climate of pittsburgh pennsylvania', 'pittsbrugh', 'un locode uspit', 'pittsburgh', 'pittsburgh frick 6–8 middle school', 'pittsburgh pennsylvania usa', 'pittsburgh style', 'city of pittsburgh', 'pittsburgh pennsylvania u s', 'st justin s high school', 'pittsburgh pa', 'glenwood pennsylvania', 'da burgh', 'pittsburgh style of literature', 'pitsburgh', 'east end pittsburgh', 'pittsburgh pennsylvania us', 'pittsburgh usa', 'smoky city', 'city of bridges', 'fort du quesne', 'pittsburg pennsylvania', 'pittsburgh frick 6 8 middle school', 'pittsburgh pennsylvania', 'pittsburgh united states of america', 'education in pittsburgh', 'pittsburg pa', 'pittsburgh pennsyvania', 'burgh', 'frick international studies academy middle school', 'pittsburgh allegheny county pennsylvania', 'pittsburgh pgh']\n",
      "Gold raw value: Pittsburgh\n",
      "Gold raw aliases (first 5): ['Smoky City', 'Pittsburgh (Pa.)', 'Pittsburgh, Pennsylvania.', 'Frick International Studies Academy Middle School', 'Pitsburgh']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"Q:\", df.loc[i, \"question\"])\n",
    "print(\"Gold normalized:\", df.loc[i, \"gold_normalized\"])\n",
    "print(\"Gold raw value:\", df.loc[i, \"gold_value_raw\"])\n",
    "print(\"Gold raw aliases (first 5):\", (df.loc[i, \"gold_aliases_raw\"] or [])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9e00b",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08484cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa4dca1f68542d0aed8b858da7717b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (8-bit) from: ../models/mistral-7b-instruct\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"../models/mistral-7b-instruct\" # \"mistralai/Mistral-7B-Instruct-v0.1\" # choose model name instead of path to local folder with model\n",
    "\n",
    "# 8-bit квантизация\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quant_config,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"Loaded (8-bit) from:\", MODEL)\n",
    "\n",
    "# паддинг\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6137a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about yourself. Who are you and how can you help me?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "attention_mask = torch.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2314770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: (1, 23)\n",
      "model.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "input_ids = input_ids.to(model.device)  # Because device is auto\n",
    "attention_mask = attention_mask.to(model.device)\n",
    "\n",
    "print(\"input_ids shape:\", tuple(input_ids.shape))\n",
    "print(\"model.device:\", model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fb1d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Tell me about yourself. Who are you and how can you help me? [/INST] I'm Mistral, a language model trained by the Mistral AI team. I'm here to help you with any language-related task you have\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out_ids = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=32,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "text = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1bc46",
   "metadata": {},
   "source": [
    "### Semantic entropy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4be338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one(model, tokenizer, question, max_new_tokens=64, temperature=1.0, top_p=0.95):\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    attention_mask = torch.ones_like(input_ids).to(model.device)\n",
    "\n",
    "    out = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        attention_mask=attention_mask,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        return_dict_in_generate=True,\n",
    "        output_logits=True,   # важно: нужны logits на каждом шаге\n",
    "    )\n",
    "\n",
    "    # generated tokens только после prompt\n",
    "    prompt_len = input_ids.shape[1]\n",
    "    seq = out.sequences[0]\n",
    "    gen_tokens = seq[prompt_len:]  # (T,)\n",
    "    # logits: tuple length T, each (batch=1, vocab)\n",
    "    logits_steps = out.logits\n",
    "\n",
    "    # log p для каждого реально выбранного токена\n",
    "    token_logprobs = []\n",
    "    for t, step_logits in enumerate(logits_steps):\n",
    "        tok = gen_tokens[t].item()\n",
    "        lp = F.log_softmax(step_logits[0], dim=-1)[tok]\n",
    "        token_logprobs.append(lp)\n",
    "\n",
    "    # средний log-likelihood токенов (как у них в коде: np.mean(log_lik)) [web:596]\n",
    "    avg_token_loglik = torch.stack(token_logprobs).mean().item() if len(token_logprobs) else float(\"-inf\")\n",
    "\n",
    "    text = tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "    return text, avg_token_loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5951c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_entropy_for_question(\n",
    "    question: str,\n",
    "    responses: list[str],\n",
    "    avg_token_logliks: list[float],\n",
    "    entailment_model,\n",
    "    strict_entailment: bool = False,\n",
    "):\n",
    "    example = {\"question\": question}\n",
    "\n",
    "    semantic_ids = get_semantic_ids(\n",
    "        responses,\n",
    "        model=entailment_model,\n",
    "        strict_entailment=strict_entailment,\n",
    "        example=example,\n",
    "    )\n",
    "\n",
    "    # p(cluster) по нормализованной сумме вероятностей ответов в кластере [web:596][web:594]\n",
    "    logp_per_cluster = logsumexp_by_id(semantic_ids, np.array(avg_token_logliks), agg=\"sum_normalized\")\n",
    "    sem_entropy = predictive_entropy_rao(np.array(logp_per_cluster))\n",
    "\n",
    "    return {\n",
    "        \"semantic_ids\": semantic_ids,\n",
    "        \"semantic_entropy\": float(sem_entropy),\n",
    "        \"logp_per_cluster\": logp_per_cluster,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17c56d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 1/10 [00:21<03:11, 21.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 2/10 [00:39<02:34, 19.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 3/10 [01:04<02:32, 21.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 4/10 [01:11<01:36, 16.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████     | 5/10 [01:14<00:57, 11.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|██████    | 6/10 [02:14<01:51, 27.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|███████   | 7/10 [03:03<01:45, 35.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|████████  | 8/10 [03:13<00:53, 26.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|█████████ | 9/10 [04:09<00:35, 35.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 10/10 [04:45<00:00, 28.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 0.559032761127394)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entailment модель для кластеризации смыслов (локально) [web:594]\n",
    "ent_model = EntailmentRoBERTa(model='../models/roberta-large-mnli')\n",
    "\n",
    "M = 10  # число сэмплов ответов на один вопрос (для демо)\n",
    "results = []\n",
    "\n",
    "for ex in tqdm(sample):  # sample = 10 items из шага 1\n",
    "    q = ex[\"question\"]\n",
    "\n",
    "    responses = []\n",
    "    avg_lls = []\n",
    "    for _ in range(M):\n",
    "        ans, avg_ll = generate_one(\n",
    "            model, tokenizer, q,\n",
    "            max_new_tokens=64,\n",
    "            temperature=1.0,\n",
    "            top_p=0.95,\n",
    "        )\n",
    "        responses.append(ans)\n",
    "        avg_lls.append(avg_ll)\n",
    "\n",
    "    sem = semantic_entropy_for_question(\n",
    "        question=q,\n",
    "        responses=responses,\n",
    "        avg_token_logliks=avg_lls,\n",
    "        entailment_model=ent_model,\n",
    "        strict_entailment=False,\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"responses\": responses,\n",
    "        \"avg_token_logliks\": avg_lls,\n",
    "        \"semantic_ids\": sem[\"semantic_ids\"],\n",
    "        \"semantic_entropy\": sem[\"semantic_entropy\"],\n",
    "    })\n",
    "\n",
    "len(results), results[0][\"semantic_entropy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d709efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q number 0: Which US city was named after a British Prime Minister?\n",
      "Semantic entropy: 0.559032761127394\n",
      "answer: Pittsburgh\n",
      "\n",
      "[cluster 0] Washington, D.C.\n",
      "[cluster 1] Pittsburgh\n",
      "[cluster 0] Washington D.C. was named after George Washington, the first President of the United States. However, the city was originally called Columbia, named after Christopher Columbus who discovered America. The name was later changed to Washington D.C. in 1790.\n",
      "[cluster 0] Washington, D.C.\n",
      "[cluster 2] The city of Baltimore in Maryland, USA was named after Sir George Calvert, 1st Baron Baltimore, who was a British Prime Minister.\n",
      "[cluster 2] Baltimore, Maryland was named after Sir George Calvert, 1st Baron Baltimore, a British Prime Minister. Calvert had also been a proprietor of the Maryland colony.\n",
      "[cluster 0] Washington D.C.\n",
      "[cluster 0] Washington, D.C. was named after George Washington, the first President of the United States. However, there is some confusion as it was originally named after the British Prime Minister, Sir George Washington. The city was later renamed in honor of the American President.\n",
      "[cluster 0] Washington D.C.\n",
      "[cluster 0] Washington D.C.\n",
      "\n",
      "\n",
      "Q number 1: Harold Holt became Prime Minister of which country in January 1966?\n",
      "Semantic entropy: 1.1946819305600997\n",
      "answer: Australia\n",
      "\n",
      "[cluster 0] Harold Holt became the Prime Minister of Australia in January 1966. He took office after the resignation of his predecessor, Lyndon B. Johnson, who was the Prime Minister of Australia from 1963 until 1966. Holt served as the Prime Minister of\n",
      "[cluster 0] Australia\n",
      "[cluster 0] Australia\n",
      "[cluster 1] Harold Holt became the Prime Minister of Australia in January 1966. He replaced Alexander Douglas-Home who had resigned earlier that month. Holt, a Liberal Party member, served as Prime Minister until his sudden death in November 1967, at the age of 55, while on\n",
      "[cluster 1] Australia\n",
      "[cluster 2] Harold Holt became the Prime Minister of Australia in January 1966. Prior to his political career, he was a prominent lawyer and served as the Governor-General of Australia.\n",
      "[cluster 2] Australia\n",
      "[cluster 3] United Kingdom\n",
      "[cluster 2] Australia\n",
      "[cluster 2] Australia\n",
      "\n",
      "\n",
      "Q number 2: The Suez Canal joins the Red Sea and which other body of water?\n",
      "Semantic entropy: -4.440892098500627e-16\n",
      "answer: Mediterranean Sea\n",
      "\n",
      "[cluster 0] Mediterranean Sea\n",
      "[cluster 0] The Suez Canal joins the Red Sea with the Mediterranean Sea. This vital waterway, located in Egypt, serves as a vital shipping lane connecting the Atlantic and Indian Oceans via the Mediterranean and Red Seas.\n",
      "[cluster 0] The Suez Canal connects the Red Sea to the Mediterranean Sea.\n",
      "[cluster 0] The Suez Canal joins the Red Sea with the Mediterranean Sea. This strategically important waterway provides a connection between the Red Sea and the Mediterranean, allowing ships to transit from one to the other without having to go around the African continent.\n",
      "[cluster 0] Mediterranean Sea\n",
      "[cluster 0] The Suez Canal connects the Red Sea to the Mediterranean Sea.\n",
      "[cluster 0] Mediterranean Sea\n",
      "[cluster 0] The Suez Canal joins the Red Sea with the Mediterranean Sea. This significant waterway serves as a vital shipping lane connecting the Middle East, Asia, Africa, and Europe, allowing maritime traffic to bypass the vast landmass of the Arabian Peninsula.\n",
      "[cluster 0] The Suez Canal joins the Red Sea with the Mediterranean Sea. This strategically important waterway connects the Indian Ocean with the Mediterranean, allowing ships to transit from one ocean to the other via the narrow canal in the Isthmus of Suez in Egypt.\n",
      "[cluster 0] The Suez Canal joins the Red Sea with the Mediterranean Sea.\n",
      "\n",
      "\n",
      "Q number 3: Selenology is the scientific study of which celestial body?\n",
      "Semantic entropy: -2.220446049250313e-16\n",
      "answer: The moon\n",
      "\n",
      "[cluster 0] The Moon\n",
      "[cluster 0] Moon\n",
      "[cluster 0] The Moon\n",
      "[cluster 0] The Moon\n",
      "[cluster 0] The Moon\n",
      "[cluster 0] The Moon\n",
      "[cluster 0] Moon\n",
      "[cluster 0] Selenology is the scientific study of the Moon. This discipline involves understanding the Moon's geology, composition, atmospheric conditions, and its impact on Earth through tidal forces and eclipses.\n",
      "[cluster 0] Moon\n",
      "[cluster 0] Moon\n",
      "\n",
      "\n",
      "Q number 4: In September 2006 the government of Prime Minister Thaksin Shinawatra was overthrown in which Asian country?\n",
      "Semantic entropy: -2.220446049250313e-16\n",
      "answer: Thailand\n",
      "\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "[cluster 0] Thailand\n",
      "\n",
      "\n",
      "Q number 5: Anatomy. Where are the intercostal muscles situated?\n",
      "Semantic entropy: 1.7570705236172954\n",
      "answer: Between the RIBS\n",
      "\n",
      "[cluster 0] The intercostal muscles are situated between the ribs. They are the muscles that are responsible for the movement of the rib cage during respiration, as well as during movements of the arms and legs. These muscles help to support the trunk and allow for movement and stability during various activities.\n",
      "[cluster 0] Intercostal muscles are located between the ribs, hence the name \"intercostal.\" They are a group of muscles that run along the length of the ribcage and help to stabilize and move the ribs during movement, such as breathing, coughing, and running. These muscles are involved in a\n",
      "[cluster 0] The intercostal muscles are situated in the chest cavity (thoracic cavity), specifically between the ribs (intercostal spaces). These muscles play a vital role in supporting and stabilizing the rib cage during movement, as well as in respiration, where they help to expand and contract the rib\n",
      "[cluster 0] The intercostal muscles are located between the ribs (intercostal space) and are responsible for moving the ribs during breathing, as well as during movement of the upper body. These muscles attach to the rib cage, specifically to the cartilage that makes up the ribs, as well as to the\n",
      "[cluster 1] The intercostal muscles are situated between the ribs. They are a group of muscles that connect the ribs to each other and help with breathing, coughing, and movements involving the thoracic cage. The intercostal muscles are divided into three groups, based on their location: the anterior intercost\n",
      "[cluster 2] The intercostal muscles are located between the ribs, specifically along the posterior surface of the ribs. There are 11 sets of intercostal muscles, numbered from 1 to 11, each of which consists of two muscles separated by a rib. These muscles are responsible for aiding in\n",
      "[cluster 3] The intercostal muscles are located between the ribs, or costae, in the thoracic cavity of the chest. There are 11 pairs of intercostal muscles, numbered from I to XI, each named according to its position between the ribs. These muscles play a critical role\n",
      "[cluster 4] Intercostal muscles are situated in between the ribs, in the chest wall. Specifically, they are located between the ribs and connect the ribs to the vertebrae and the sternum, forming the respiratory and thoracic diaphragms. The intercostal muscles\n",
      "[cluster 5] Intercostal muscles are situated between the ribs. They attach to the cartilage at the top of the ribs and to the chest wall or the abdominal wall at the bottom. Intercostal muscles are responsible for the movement of the rib cage during respiration and other activities, such as running and\n",
      "[cluster 6] Intercostal muscles are found in between the ribs, in the thoracic cavity of the chest wall. There are 11 pairs of intercostal muscles, with each pair serving a different function in movement and breathing. The intercostal muscles attach to the ribs above and below them,\n",
      "\n",
      "\n",
      "Q number 6: Who first drew Mickey Mouse when ?Disney first supplied the voice?\n",
      "Semantic entropy: 1.962819935988058\n",
      "answer: Ub Iwerks\n",
      "\n",
      "[cluster 0] Walt Disney first drew Mickey Mouse in 1928, and Disney provided the voice of Mickey Mouse for the first time in the 1928 short film \"Steamboat Willie.\"\n",
      "[cluster 0] Mickey Mouse was first drawn by Walt Disney in 1928. Disney first supplied the voice for Mickey Mouse in the short film \"Steamboat Willie\" in 1928, which introduced him to the world.\n",
      "[cluster 1] Mickey Mouse was first drawn by Walt Disney in 1928. The first voice provided for Mickey Mouse was that of Ub Iwerks, who voiced Mickey in the short film \"Steamboat Willie\".\n",
      "[cluster 2] Mickey Mouse was first drawn by Ub Iwerks, a Disney animator, in 1928. The first time Disney supplied the voice for Mickey Mouse was in the 1930 short film \"Steamboat Willie,\" where Walt Disney himself voiced Mickey. However\n",
      "[cluster 3] Mickey Mouse was first drawn by Walt Disney in 1923 or 1924. The exact date is not certain.\n",
      "\n",
      "The first voice actor to portray Mickey Mouse in cartoons was Walter Whitman. The character first appeared in \"Steamboat Willie\" on November\n",
      "[cluster 4] Mickey Mouse was first drawn by Ub Iwerks in 1928. Disney first supplied the voice for Mickey Mouse in the \"Steamboat Willie\" short film in 1928, which was also the first synchronized sound cartoon. The voice of Mickey was provided\n",
      "[cluster 5] Mickey Mouse was first drawn by Walt Disney and Ub Iwerks in 1928. Disney first supplied the voice of Mickey Mouse in 1928.\n",
      "[cluster 4] Mickey Mouse was first drawn by Ub Iwerks in 1928. Walt Disney first supplied the voice for Mickey Mouse in the short film \"Steamboat Willie\" in 1928.\n",
      "[cluster 6] Mickey Mouse was first drawn by Walt Disney in the 1920s. The first voice provided for Mickey Mouse was Walt Disney himself. However, later Disney films featured the voices of other actors, including Walt Disney, and nowadays the character is typically voiced by a famous actor or actress known for\n",
      "[cluster 7] Mickey Mouse was first drawn by Walt Disney in 1928. The first voice to supply the voice of Mickey Mouse was Ollie North.\n",
      "\n",
      "\n",
      "Q number 7: A quadruped is an animal with how many feet?\n",
      "Semantic entropy: -2.220446049250313e-16\n",
      "answer: Four\n",
      "\n",
      "[cluster 0] Four feet.\n",
      "[cluster 0] A quadruped is an animal with four feet.\n",
      "[cluster 0] Four feet.\n",
      "[cluster 0] A quadruped is an animal with four feet.\n",
      "[cluster 0] A quadruped is an animal with four feet.\n",
      "[cluster 0] Four feet.\n",
      "[cluster 0] A quadruped is an animal with four feet.\n",
      "[cluster 0] A quadruped is an animal with four feet.\n",
      "[cluster 0] A quadruped is an animal with four feet.\n",
      "[cluster 0] Four feet.\n",
      "\n",
      "\n",
      "Q number 8: Who was part man, part machine, all cop and hailed from a futuristic Detroit?\n",
      "Semantic entropy: 1.7807898925466472\n",
      "answer: Robocop\n",
      "\n",
      "[cluster 0] The answer is RoboCop. RoboCop is a character from a futuristic Detroit, who is part man and part machine, and serves as a police officer.\n",
      "[cluster 0] The character you're referring to is most likely RoboCop. He is a cyborg police officer from the futuristic city of Detroit, created by Paul Verhoeven and Ed Neumeier.\n",
      "[cluster 1] The character you're referring to is RoboCop, a fictional cybernetic police officer created by writer Frank Miller and artist Kevin Pucek, and later made famous by the 1987 movie of the same name. RoboCop is a part-man, part-machine being who is program\n",
      "[cluster 2] The answer is Cyborg. Cyborg is a character from DC Comics who was created by writer Denny O'Neil and artist Neal Adams. He first appeared in \"Green Lantern/Green Arrow\" #76 in February 1980. Cyborg is part man, part machine\n",
      "[cluster 0] The character you're referring to is likely Robocop. This iconic character combines human and robot components and is known for his role as a police officer in the futuristic city of Detroit. Robocop first appeared in comic books and later gained popularity through film and television.\n",
      "[cluster 3] The answer is Cyborg. Cyborg is a character from the DC Comics universe, specifically from the Teen Titans team. He was created by Marv Wolfman and George Perez in 1980. Cyborg is a human-cyborg hybrid who was raised by the government as an experimental\n",
      "[cluster 4] The character you're referring to is RoboCop, a popular fictional character and the titular protagonist of the \"RoboCop\" film series. He was a heavily armed, cyborg police officer who combines human intelligence and emotion with advanced machinery and weapons, and is set in a futuristic\n",
      "[cluster 5] The character you're referring to is RoboCop. Created by writer Frank Miller and filmmaker Irvin Kershner, RoboCop first appeared in a 1987 motion picture of the same name. RoboCop is part man, part machine, and all cop, serving as an en\n",
      "[cluster 0] The character you're referring to is likely Robocop, a fictional police officer who combines human attributes with advanced technology. He is a popular character in the comic book and film industries. Robocop hails from a futuristic Detroit, where crime is rampant and societal problems are many.\n",
      "[cluster 6] The character you're referring to is likely \"RoboCop.\" RoboCop is a fictional police officer who appears in several comic book series and films. He was created by writer Frank Miller and artist Kevin O'Neill, and first appeared in Marvel Comics' \"Amazing Heroes\" #1\n",
      "\n",
      "\n",
      "Q number 9: What kind of disaster claimed some 100,000 lives in Armenia in 1988?\n",
      "Semantic entropy: 0.5636215059647229\n",
      "answer: Earthquake\n",
      "\n",
      "[cluster 0] Earthquake\n",
      "[cluster 0] Earthquake\n",
      "[cluster 1] Ah, my dear interlocutor, you have delved into the annals of history and posed a question that stirs the very soul of every Armenian. The cataclysmic event to which you refer, the one that claimed the lives of 100,000 souls in\n",
      "[cluster 0] The disaster that claimed some 100,000 lives in Armenia in 1988 was an earthquake. It hit the northern part of the country near the capital Yerevan on December 7th, causing widespread destruction and loss of life. The earthquake, one of the dead\n",
      "[cluster 0] The disaster was an earthquake that struck Armenia's capital, Yerevan, on December 7, 1988. The earthquake, one of the deadliest ever to hit the region, was followed by a series of aftershocks, and many people were left homeless or trapped in the\n",
      "[cluster 0] The earthquake of 1988 in Armenia was a major disaster that claimed around 100,000 lives. The quake was one of the deadliest natural disasters in the history of the country. The magnitude 6.0 earthquake struck the Soviet-era Armenian city\n",
      "[cluster 0] The disaster that claimed some 100,000 lives in Armenia in 1988 was an earthquake. Specifically, it was a 7.5 magnitude earthquake that occurred on December 7, 1988, in the Armenian city of Spitak.\n",
      "[cluster 0] The Armenian earthquake of 1988\n",
      "[cluster 2] The Nagorno-Karabakh conflict\n",
      "[cluster 0] Earthquake\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sample)):\n",
    "    print(f\"Q number {i}:\", results[i][\"question\"])\n",
    "    print(\"Semantic entropy:\", results[i][\"semantic_entropy\"])\n",
    "    print(f\"answer: {sample[i]['answer']['value']}\")\n",
    "    print()\n",
    "\n",
    "    for r, sid in zip(results[i][\"responses\"], results[i][\"semantic_ids\"]):\n",
    "        print(f\"[cluster {sid}] {r}\")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
